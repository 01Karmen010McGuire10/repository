---
title: Learning Linked Data Workshop Notes
date: '2017-09-01T16:21:09+01:00'
description: 
draft: false
creators: []
contributors: []
publisher: 
tags: []
aliases:
- "/archive/mediawiki_wiki/Learning_Linked_Data_Workshop_Notes.html"
---

 **This is an archived MediaWiki page.**  
This page was last modified on 13 Mar 2012, at 05:45.  
This page has been accessed 2,020 times.

<table id="toc" class="toc">
  <tr>
    <td>
      <div id="toctitle">
        <h2>Contents</h2>
      </div>
      <ul>
        <li class="toclevel-1 tocsection-1"><a href="#This_document_in_context_.28March_2012.29"><span class="tocnumber">1</span> <span class="toctext">This document in context (March 2012)</span></a></li>
        <li class="toclevel-1 tocsection-2">
          <a href="#Learning_Linked_Data_Project_Workshop.2C_2-3_February_2012_--_Meeting_Notes"><span class="tocnumber">2</span> <span class="toctext">Learning Linked Data Project Workshop, 2-3 February 2012 -- Meeting Notes</span></a>
          <ul>
            <li class="toclevel-2 tocsection-3"><a href="#Key_points_of_reference"><span class="tocnumber">2.1</span> <span class="toctext">Key points of reference</span></a></li>
            <li class="toclevel-2 tocsection-4">
              <a href="#Thursday.2C_February_2nd.2C_2012"><span class="tocnumber">2.2</span> <span class="toctext">Thursday, February 2nd, 2012</span></a>
              <ul>
                <li class="toclevel-3 tocsection-5"><a href="#Initial_walk-through_of_Inventory_of_Learning_Topics"><span class="tocnumber">2.2.1</span> <span class="toctext">Initial walk-through of Inventory of Learning Topics</span></a></li>
                <li class="toclevel-3 tocsection-6"><a href="#Start_focusing_on_top-level_Learning_Topics"><span class="tocnumber">2.2.2</span> <span class="toctext">Start focusing on top-level Learning Topics</span></a></li>
                <li class="toclevel-3 tocsection-7">
                  <a href="#After_Thursday_afternoon_break"><span class="tocnumber">2.2.3</span> <span class="toctext">After Thursday afternoon break</span></a>
                  <ul>
                    <li class="toclevel-4 tocsection-8"><a href="#Should_Singapore_Framework-based_design_be_supported.3F"><span class="tocnumber">2.2.3.1</span> <span class="toctext">Should Singapore Framework-based design be supported?</span></a></li>
                  </ul>
                </li>
                <li class="toclevel-3 tocsection-9"><a href="#Takeaways_and_Next_Steps"><span class="tocnumber">2.2.4</span> <span class="toctext">Takeaways and Next Steps</span></a></li>
              </ul>
            </li>
            <li class="toclevel-2 tocsection-10">
              <a href="#Friday.2C_3_February_2012"><span class="tocnumber">2.3</span> <span class="toctext">Friday, 3 February 2012</span></a>
              <ul>
                <li class="toclevel-3 tocsection-11"><a href="#Resuming_at_10:15_AM"><span class="tocnumber">2.3.1</span> <span class="toctext">Resuming at 10:15 AM</span></a></li>
                <li class="toclevel-3 tocsection-12"><a href="#Querying"><span class="tocnumber">2.3.2</span> <span class="toctext">Querying</span></a></li>
                <li class="toclevel-3 tocsection-13"><a href="#Composing"><span class="tocnumber">2.3.3</span> <span class="toctext">Composing</span></a></li>
                <li class="toclevel-3 tocsection-14"><a href="#Native_RDF_terminology_versus_library-world_terminology"><span class="tocnumber">2.3.4</span> <span class="toctext">Native RDF terminology versus library-world terminology</span></a></li>
                <li class="toclevel-3 tocsection-15">
                  <a href="#Resume_at_1:00_PM"><span class="tocnumber">2.3.5</span> <span class="toctext">Resume at 1:00 PM</span></a>
                  <ul>
                    <li class="toclevel-4 tocsection-16"><a href="#Domain_Model.3F"><span class="tocnumber">2.3.5.1</span> <span class="toctext">Domain Model?</span></a></li>
                    <li class="toclevel-4 tocsection-17"><a href="#Publishing..."><span class="tocnumber">2.3.5.2</span> <span class="toctext">Publishing...</span></a></li>
                    <li class="toclevel-4 tocsection-18"><a href="#Storing..."><span class="tocnumber">2.3.5.3</span> <span class="toctext">Storing...</span></a></li>
                    <li class="toclevel-4 tocsection-19"><a href="#Associating_Learning_Topics_with_Tool_Categories"><span class="tocnumber">2.3.5.4</span> <span class="toctext">Associating Learning Topics with Tool Categories</span></a></li>
                  </ul>
                </li>
                <li class="toclevel-3 tocsection-20"><a href="#Resuming_at_3:15_PM"><span class="tocnumber">2.3.6</span> <span class="toctext">Resuming at 3:15 PM</span></a></li>
                <li class="toclevel-3 tocsection-21"><a href="#Use_Cases"><span class="tocnumber">2.3.7</span> <span class="toctext">Use Cases</span></a></li>
                <li class="toclevel-3 tocsection-22"><a href="#Tools"><span class="tocnumber">2.3.8</span> <span class="toctext">Tools</span></a></li>
                <li class="toclevel-3 tocsection-23"><a href="#Composiing_.28creating_data.29"><span class="tocnumber">2.3.9</span> <span class="toctext">Composiing (creating data)</span></a></li>
                <li class="toclevel-3 tocsection-24">
                  <a href="#Mapping_tools"><span class="tocnumber">2.3.10</span> <span class="toctext">Mapping tools</span></a>
                  <ul>
                    <li class="toclevel-4 tocsection-25"><a href="#Querying_2"><span class="tocnumber">2.3.10.1</span> <span class="toctext">Querying</span></a></li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </td>
  </tr>
</table>

#### This document in context (March 2012) 
<dl>
<dt><a href="/archive/mediawiki_wiki/Learning_Linked_Data_Topics" class="external text" rel="nofollow">Inventory of Learning Topics</a></dt>
<dd> For internal review 13 March through 2 April, after which the text will be posted for wider review on a UW blog.
</dd>
<dt><a href="/archive/mediawiki_wiki/Learning_Linked_Data_Workshop_Minutes" class="external text" rel="nofollow">Seattle Workshop Minutes</a></dt>
<dd> Three-page summary of key discussion points and actions.
</dd>
<dt><a href="/archive/mediawiki_wiki/Learning_Linked_Data_Workshop_Notes" class="external text" rel="nofollow">Seattle Workshop Notes</a></dt>
<dd> <i><b>THIS DOCUMENT -- forty-page edited transcript of workshop discussion as a reference on points of detail.</b></i>
</dd>
<dt><a href="/archive/mediawiki_wiki/Learning_Linked_Data_Workshop" class="external text" rel="nofollow">Learning Linked Data Project</a></dt>
<dd> Main wiki page for the project, with links to the project proposal, timeline, list of participants, mailing-list archive, and all wiki drafts produced to date.
</dd>
</dl>

# **Learning Linked Data Project Workshop, 2-3 February 2012 -- Meeting Notes** 
<dl>
<dt>Agenda</dt>
<dd> <a href="/archive/mediawiki_wiki/Learning_Linked_Data/Agenda" class="external free" rel="nofollow">/archive/mediawiki_wiki/Learning_Linked_Data/Agenda</a>
</dd>
<dt>Attendees</dt>
<dd> Tom Baker, Joseph Tennis, Marjorie Hlava, Riley Stormer, Marcia Zeng, David Talley, Joseph Busch, Karen Wickett, Corey Harper, Ed Summers, Craig Willis, Diane Hillmann, Karen Coyle, Randy Orwin, Stuart Sutton, Mike Crandall
</dd>
</dl>

##### Key points of reference 
<dl>
<dt>
<a href="/archive/mediawiki_wiki/files/IMLSPlanningGrantNarrative.pdf" class="external text" rel="nofollow">IMLS Grant Narrative</a>
</dt>
<dd>What we proposed to do in the grant (and in this key workshop).
</dd>
<dt>
<a href="/archive/mediawiki_wiki/Learning_Linked_Data_Inventory" title="Learning Linked Data Inventory">Inventory of Learning Topics</a>
</dt>
<dd>Topics and skills related to Linked Data, the learning of which would be supported by the tool platform proposed in a deliverable of the Learning Linked Data Project (topics such as "vocabulary", "application design", and "visualization"). This document will be the focus of our discussion.
</dd>
</dl>

## Thursday, February 2nd, 2012 

Attendees introduce themselves. Backgrounds include academia, IT development and deployment, software, LIS, metadata design and application.

### Initial walk-through of [Inventory of Learning Topics](/archive/mediawiki_wiki/Learning_Linked_Data_Inventory "Learning Linked Data Inventory") 
<dl>
<dt>Tom</dt>
<dd> Intended Results from today and tomorrow:
<ul>
<li> Set of requirements for a tech software platform for metadata design using descriptive languages
</li>
<li> Wireframe the platform
</li>
<li> Begin assessing 
</li>
</ul>
<dl><dd>
<ul>
<li> Need for Open Source tool development based on these requirements and effort required (needed for developing 2013 IMLS project proposal)
</li>
<li> Documentation requirements regarding platform use and deployment
</li>
</ul>
</dd></dl>

</dd>
</dl>
<dl><dd>Let's begin with a walk-through of the <a href="/archive/mediawiki_wiki/Learning_Linked_Data_Inventory" title="Learning Linked Data Inventory">Inventory of Learning Topics</a>. (Tom distributes Post-Its and asks participants to write down the inventory items - skills and learning topics such as "graphs", "merging triples", "Open World Assumption" - for later clustering on the wall.)
</dd></dl>
<dl>
<dt>Corey</dt>
<dd> We should consider skills in relation to personas, eg, the intended audience and expected outcomes, and obstacles each audience will face. These inventory items will differ in difficulty among persona, given their levels of understanding.
</dd>
<dt>Marjorie</dt>
<dd> Our list of personas and audiences should also include outsiders and non-traditional users, such as software companies and marketing firms.
</dd>
<dt>Tom</dt>
<dd> I suggest we group the audience by learning environment rather than field. We want to create a teaching platform that will accommodate multiple audiences and learning styles.
</dd>
<dd>
<b><a href="/archive/mediawiki_wiki/Learning_Linked_Data_Inventory" title="Learning Linked Data Inventory">Learning Topics</a></b>: <i><b>Intended or desired learning outcome resulting from use of the outlined platform, i.e., being able to analyze, synthesize, apply the knowledge gained.</b></i> The Inventory list consists of skills required and methods to teach them.
</dd>
<dt>Diane</dt>
<dd> Assigning difficulty levels or expected personas won't apply across the diverse spectrum of users' backgrounds. For example, some may lack basics in Knowledge Organization; others Information Technology. We need to know the user in order to know where to begin.
</dd>
<dt>JosephT</dt>
<dd> The combination of libraries, technology, and datasets creates a whole new baseline audience rather than those who do or don't know assumed subjects. Rather, try to approach the subject from the domain of Linked Data (beginners).
</dd>
<dt>Randy</dt>
<dd> <i><b>Presumed outcomes vary by student or user. Assessment-based teaching (is oriented) toward presumed outcomes.</b></i> Not every student will end up with the same outcome or experiences (which is good).
</dd>
<dt>Stuart</dt>
<dd> <i><b>Outcomes are rigid in some aspects in that students need to acquire a certain level of mastery.</b></i> The core assumptions should be reevaluated and (perhaps) redesigned.
</dd>
<dt>Mike</dt>
<dd> <i><b>Learning outcomes are selected and recombined for given audiences based on the intention of a course.</b></i>
</dd>
<dt>Stuart</dt>
<dd> Distinguish what a 'competent' user would know versus what a baseline audience would know. <i><b>Distinguish 'competent' and 'baseline' audiences.</b></i>
</dd>
<dt>Diane</dt>
<dd> The motivation of the user or persona also affects the expected learning outcome: understand enough to use it, or also to innovate (e.g., for thought leaders, designers, IT implementers)?
</dd>
</dl>

### Start focusing on top-level [Learning Topics](/archive/mediawiki_wiki/Learning_Linked_Data_Inventory "Learning Linked Data Inventory") 
<dl>
<dt>Tom</dt>
<dd> Let's stop looking at the details at focus on the top-level headings: "Reading linked data", in turn divided into "grammar", "vocabulary", and "syntax (abstract and concrete)". To what extent is this about understanding the concepts underlying Linked Data as opposed to actually creating Linked Data applications? Do we assume we are aiming at giving the intended audience a high-level understanding of RDF?
</dd>
<dt>Mike</dt>
<dd> Grant proposal says: academic platform to help people learn about Linked Data, with emphasis on the tools to do so. The intent is to design the tool set used by teachers to accomplish high-level understanding to more technical implementations. Functional requirements should be laid out in advance of audience definition or vice versa. The understanding of concepts will not necessarily come from using tools.
</dd>
<dt>Craig</dt>
<dd> Systems don't come with built-in end-to-end teaching materials, but users still accomplish end goals through working with teachers using curricula that address the system basics.
</dd>
<dt>Mike</dt>
<dd> Tools to teach metadata and the tool itself both need to be defined. <i><b>The tools for teaching are also the tools for applying.</b></i>
</dd>
<dt>Stuart</dt>
<dd> Skills are listed in the inventory which may or may not require tools (i.e., tools that must also be taught).
</dd>
<dt>Tom</dt>
<dd> Synthesis of audience and learning outcomes in the context of the tool platform. Which results need "tool support" and what prerequisites would be required in such cases?
</dd>
<dt>Marjorie</dt>
<dd> Grant scope outlines the description and expected outcomes of the tools development: e.g., that students will be able to interpret, design, and use languages of description. Questions regarding actually creating the languages of description vs. understanding existing languages of description and metadata design. Is the tool platform intended to be more for supporting the teaching of languages of description or for supporting the creation of metadata using languages of description?
</dd>
<dt>Corey (from the grant)</dt>
<dd> "Language lab for learners and designers of Languages of Description": people who want to learn to build and use these languages.
</dd>
</dl>

### After Thursday afternoon break 
<dl>
<dt>Tom</dt>
<dd> <i><b>To re-state the intent: this is not about curriculum design but about designing a tool platform that enables teachers to create courses aimed at various different types of users. Editors, visualizers, search engines, triple stores that will be embedded in teaching environments.</b></i>
</dd>
<dt>Corey</dt>
<dd> Here's an example of a Linked Data tool we might leverage or reference: the <i><b><a href="http://stack.lod2.eu/" class="external text" rel="nofollow">LOD2</a> stack</b></i> developed by an EU project -- <i><b>an Ubuntu image that holds an operating system preloaded with Linked Data tools</b></i>.
</dd>
<dt>Stuart</dt>
<dd> Perhaps the tool is a more flexible hub in which different tools, engines, development environments, triple stores, etc. can all be housed to which educators can direct users in their course work and development (curriculum independent). Support of learning environments through a given tool set rather than a specific tool or platform that must be used.
</dd>
<dt>Karen C.</dt>
<dd> How would this hub/environment differ from any others in use currently?
</dd>
<dt>Joseph T.</dt>
<dd> What tools would be needed to accomplish the Learning Objectives outlined elsewhere?
</dd>
<dt>Corey</dt>
<dd> <a href="http://www.codecademy.com/" class="external text" rel="nofollow">Codecademy</a>: OS platform to custom-tailor code development curricula which could specifically be customized for Linked Data objectives.
</dd>
<dt>Stuart</dt>
<dd> The tool should include training, resource, and development needs to address the different users.
</dd>
<dt>Tom</dt>
<dd> Is there a tool set that exists (or could be developed) that ties together the creation, development, and deployment of Linked Data through each iteration? A <i><b>virtual palette of software functionality</b></i> that allows different curricula to be developed from one source. A built-in triple store would also benefit the development and teaching environment, akin to the texts and tools available in a foreign language lab.
</dd>
<dt>Marcia</dt>
<dd> "Tool" means more than just software functionality. The toolset provides methods for assessing data and developing skills. Whether it is done programmatically is irrelevant. 
</dd>
<dt>Stuart</dt>
<dd> Assessment is part of the pedagogy and learning environment, not necessarily a tool. However, this is from the academic standpoint where the need is placed on a "real-world" application Linked Data rather than skill assessment.
</dd>
<dt>Tom</dt>
<dd> Thus the emphasis on documenting best practices, uses, and the toolset itself. 
</dd>
<dt>Cory</dt>
<dd> <i><b>How should the tool platform be packaged? More as a set of documentation on how to use a set of tools? Or more as an integrated tool platform, designed for a specific OS, that includes documentation on its use?</b></i>
</dd>
<dt>Tom</dt>
<dd> The limited scope and funding from a (future) IMLS grant may preclude totally defining the "packaging" of the toolkit.
</dd>
<dt>Corey</dt>
<dd> <i><b>Technology is always evolving. This tool will be a snapshot of the toolset at one point in time. Each iteration will change the uses and development of the tool.</b></i>
</dd>
<dt>Ed</dt>
<dd> How are we defining the simulated tool environment vs. real-world simulation in which users are prepared for real-world application of Linked Data information?
</dd>
<dt>Stuart</dt>
<dd> <i><b>The tool is a means of preparing users for real-world use of Linked Data. The intention of the tool, if developed, should be a jumping off point rather than all-encompassing.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Our goal is to identify existing tools and document them in order to meet the teaching/learning objectives outlined in the grant.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>This could be a hub or orchestrator of tools rather than a newly developed tool or environment. Fill the gap between how the software works and how it is applied in the context of learning Linked Data.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>The environment of Linked Data is the Web. Users therefore need the basics of web applications, triple stores, RDF, etc.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>As an example, a real-world application might be a request to create a Linked Data app out of an infobase of questionable quality. How does one learn to take undifferentiated data and parse it into RDF/Linked Data. Thus the need for XML knowledge, programming, data transformation knowledge is essential.</b></i>
</dd>
<dt>Diane</dt>
<dd> In a sense, this is an attempt to ameliorate the communication between catalogers and programmers/Linked Data developers in a simplified manner, the goal being a uniform outcome of two different indexing languages used to describe the same thing.
</dd>
<dt>Marjorie</dt>
<dd> The need to demonstrate the uses and values of Linked Data is also important for the toolset. The toolset will then lead to actual deployment. The diversity of data sources adds a layer of complexity before the tool itself is approached.  
</dd>
<dt>List A (from Karen)</dt>
<dd> How it relates to List B...
</dd>
</dl>

- Examples of what's possible (which open doors for users/students/clients to build whole new applications. (List A)
- How to assess, parse and validate data. (List A)
  - Relates to Learning Topic "Assessing" (List B)
- How to create, change, improve the basic triples (List A)
  - Relates to Learning Topic "Composing" (List B)
- How to query data (List A)
  - Relates to Learning Topic "Querying" (List B)
<dl>
<dt>Stuart</dt>
<dd> Are we assuming that any data in this case already exists? Design leads to the data.
</dd>
<dt>Marjorie</dt>
<dd> this falls in the what's possible category in which one has a blob with which they want to create a Linked Data application. Thus new schemas are created from that.
</dd>
<dt>Craig</dt>
<dd> Creating new Linked Data from scratch and creating Linked Data from existing (non-Linked) data are two different approaches.
</dd>
<dt>Karen C.</dt>
<dd> Pedagogically both seem valid. Starting with a given data set versus determining a new data set from which to build schemas and metadata. Where should the starting point be for new students?
</dd>
<dt>Diane</dt>
<dd> Making a foreign concept relevant is important in order to engage the user.
</dd>
<dt>Craig</dt>
<dd> What exactly does cleaning the dataset entail? What about when there is structure but no metadata per se? 
</dd>
<dt>Joseph B.</dt>
<dd> For example, creating the schema from unstructured data or using incompatible metadata, which is "better" or more useful? Similar to starting with no data and a schema or starting with a blob of data and no schema.
</dd>
<dt>Diane</dt>
<dd> Assessment of the data is essential in any case in order to know and understand the information. Assessing where it is and where you want it to go, as well as content value. Data prioritization becomes key (thus an underlying comprehension of the info is required) and what "improvements" will result. The endpoint is hopefully an evolving indexing language that accommodates growth which is understood/developed by the high-level cataloger rather than the tool developer.
</dd>
<dt>Corey</dt>
<dd> What about the situations where there is no metadata, e.g., LAM data from inherited content? How does one approach this information in difference from the academic problem posed.
</dd>
<dt>Karen W</dt>
<dd> The goal should be taking a baseline user, hand them any sort of the above-mentioned data, and have them create a diagram and assessment outlining the metadata. 
</dd>
<dt>Diane</dt>
<dd> Similarly, the outcome should include an ability to assess the metadata and data.
</dd>
<dt>Marcia</dt>
<dd> <i><b>The tool could use a "kitchen" metaphor -- a kitchen in which anyone can cook what they desire. Learning metadata and learning Linked Data are two related topics that could extend to the grants tool scope. For LIS students, the interest is in learning Linked Data. IT students may need to acquire more insight into cataloging and metadata best practices.</b></i>
</dd>
<dt>Tom</dt>
<dd> Is "Assessing, validating, and parsing" a corollary to "reading" in the inventory?
</dd>
<dt>Corey</dt>
<dd> <i><b>We should be careful not to conflate the software notion of "reading" (reading triples) with a more content-oriented, LIS type of assessment ("reading") of the metadata.</b></i>
</dd>
<dt>Tom</dt>
<dd> The Reading category has multiple dimensions: Grammar, Vocabularies, concrete syntaxes, etc.
</dd>
<dt>Marjorie</dt>
<dd> Moving forward, these facets should be broken out from the Reading category.
</dd>
<dt>Stuart</dt>
<dd> List A could constitute a pedagogical approach while List B is an expected outcome from that approach. In which case the need for a curriculum based on these outcomes mirrors each list.
</dd>
<dt>Diane</dt>
<dd> List A uses vocabulary that students and educators are familiar with and can leverage.
</dd>
<dt>Karen W.</dt>
<dd> Vocabulary could be course-based knowledge (skill and vocabulary set that allows users to move to the next phase of Linked Data development).
</dd>
<dt>Tom</dt>
<dd> Distinguish the courses from the inventory list of expected outcomes. Users have to read and understand the information at hand before engaging with any tool.
</dd>
<dt>Karen C.</dt>
<dd> The inventory appears just to address learning RDF rather than a holistic approach to Linked Data or metadata. A balance must be struck to create a basic understanding of Linked Data and how to assess, read, or approach the concepts.
</dd>
<dt>Joseph T.</dt>
<dd> How do we scope a Linked Data project that doesn't necessarily leverage RDF? Should RDF be a starting point or the entirety of the course? How to define this in the parameters of the grant requirements?
</dd>
<dt>Craig</dt>
<dd> RDF can be a starting point to leverage the concepts of Linked Data and how to approach it. It is only one path through Linked Data concepts.
</dd>
<dt>Stuart?</dt>
<dd> <i><b>The toolset should be a jumping-off point for learning Linked Data concepts, not for learning specific tools or vocabularies.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> "Manipulating the data" should be dropped as a separate item since it conflates so many aspects. (We drop "manipulating" as a separate category.)
</dd>
</dl>

#### Should Singapore Framework-based design be supported? 
<dl>
<dt>Tom</dt>
<dd> Is the Singapore framework a good fit for the high-level categories and approaches? Should Functional Requirements and Domain Modeling fall within the scope of the tool platform?
</dd>
<dt>Marcia</dt>
<dd> Domain Modeling is essential in metadata development.
</dd>
<dt>Joseph T</dt>
<dd> Are Functional Requirements needed in each case? In the wild, perhaps not; however, the concept and scope of the tool dictate what detail is needed.
</dd>
<dt>Joseph T</dt>
<dd> <i><b>The baseline should be describing and teaching Linked Data and its behavior on the Web rather than on creating domain-specific data, or data from scratch.</b></i>
</dd>
<dt>Karen W</dt>
<dd> In a tool platform, what tools would support learning about domain modeling (i.e., tools that aren't already available for standard user). Similarly, what tools could address functional requirements as they pertain to Linked Data.
</dd>
<dt>Someone...</dt>
<dd> If the intent of the grant is to build a toolkit that allows users to express and create Linked Data information, is the curriculum also part of the toolkit or a separate endeavor? Moving from a given dataset to a set of Linked Data (including domain modeling and FR) is the complete Singapore framework approach to the Linked Data toolset.
</dd>
<dt>Tom</dt>
<dd> I was picturing mind-mapping tool that would help people brainstorm Domain Models, maybe even saving the results as RDF.
</dd>
</dl>

### Takeaways and Next Steps 
<dl>
<dt>Tom</dt>
<dd> Tomorrow, let's continue the refinement of high-level Learning Topics. Recall that the goal is to specify a toolkit that allows both educators and end-users understand (on varying levels) Linked Data concepts. Eventually, we will need to discuss whether this means specifying a new toolkit or something more like a hub or orchestrator that consolidates existing tools into one toolkit. Of interest, though out of scope, is a curriculum or pedagogy for instructors to leverage this toolkit.
</dd>
</dl>

## Friday, 3 February 2012 
<dl>
<dt>Tom</dt>
<dd> Let's put three categories on the whiteboard (from left to right): "prerequisites" for the learning topics, "learning topics" (the biggest category and our main focus), and "things that are out of scope" (such as advanced ontology engineering). (Tom divides the whiteboard into three parts.) We need to focus on the learning topics that is relevant to the tool platform we envision.
</dd>
<dt>Tom</dt>
<dd> Before we dig into this, I'd like to address the issue of "non-RDF Linked Data". We don't want to get bogged down in the debate over whether non-RDF linked data is "really" linked data, because if it is data and it is linked, then it is in some sense linked data. Linked data is not just RDF-based -- many people feel very strongly about that. However, we want to focus on RDF-based Linked Data, and this should provide the scope of the proposed tool platform.
</dd>
<dd>ACTION 2012-02-03 for Marjorie, Corey, and ?Ed: <i><b>Write up a paragraph or two on "non-RDF Linked Data".</b></i>
</dd>
<dt>Corey</dt>
<dd> I am concerned that alot of the core concepts we have been discussing can be applied to lots of other things, including APIs and non-RDF Linked Data.
</dd>
<dt>Marjorie</dt>
<dd> Agreed.
</dd>
<dt>Karen C</dt>
<dd> If I have three URIs, how do I know they are Linked Data?
</dd>
<dt>Corey</dt>
<dd> You dereference the middle URI.
</dd>
<dt>Tom</dt>
<dd> <i><b>Marjie's proposed use case was very instructive. I'd like to come away from the meeting with everyone having an assignment: everyone in the room has a differing pedagogical concept in mind -- what Stuart calls use cases. Everyone should write up (one of) their use cases and specify how these concepts map to the learning topics within the scope of the toolkit.</b></i>
</dd>
<dd>ACTION 2012-02-03 for everyone, starting with Stuart: <i><b>Write up a brief use case describing a pedagogical approach to teaching (or learning) Linked Data, specifying how the elements of their approach map to Learning Topics.</b></i>
</dd>
<dt>Tom</dt>
<dd> In other words, write up not just use cases, but use cases specifically related to the Learning Topics. The use cases will provide some pedagogical concepts as context and illustration. The platform and use cases will form part of the same package of deliverables, though they differ in intent.
</dd>
<dt>Karen</dt>
<dd> I see a gap: there are not tools listed for creating links.
</dd>
<dt>Ed</dt>
<dd> Could be included under composing.
</dd>
<dt>Tom</dt>
<dd> Is "discovering relationships" part of that?
</dd>
<dt>Karen</dt>
<dd> This is less about "discovering relationships" and more about "discovering properties".
</dd>
<dt>Stuart</dt>
<dd> Students ask: how do I find this stuff?
</dd>
<dt>Karen</dt>
<dd> We talk about how to become part of the Linked Data cloud, part of that is reusing vocabularies. LCSH has exposed URIs, though it isn't used much.
</dd>
<dt>Ed</dt>
<dd> It's used quite a bit.
</dd>
<dt>Karen</dt>
<dd> The word "mapping" makes more sense to me than "alignment".
</dd>
<dt>Stuart</dt>
<dd> I work a lot in educational standards, and in that field, "alignment" is an assertion of equality.
</dd>
<dt>Joseph</dt>
<dd> Mapping is more exclusive.
</dd>
<dt>Stuart</dt>
<dd> "Alignment" is a subclass of "mapping" ;-) Clearly, we should write out some definitions.
</dd>
<dt>ACTION 2012-02-03 for Tom</dt>
<dd> <i><b>Propose definitions for concepts mentioned in the inventory of Learning Topics.</b></i>
</dd>
<dt>Randy</dt>
<dd> Definitions would really help someone like me who is not acquainted well with Linked Data.
</dd>
<dt>Tom</dt>
<dd> Stuart, what is a "learning outcome" in the context of curriculum development? It's useful to distinguish to between Learning Topics and Learning Outcomes.
</dd>
<dt>Stuart</dt>
<dd> <i><b>An Outcome would start with "At the completion of this course, students will be able to..." and describe the ability, whether encoding in RDF/XML or creating an application profile. Any of these Learning Topics can be associated with Learning Outcomes.</b></i>
</dd>
<dt>Tom</dt>
<dd> We need to get consensus on the learning topics list. How should we do this? Walking through it with Karen's list. Which of these topics are prerequisites competencies?
</dd>
<dt>Corey</dt>
<dd> Before we go through the details we should separate out "syntaxes".
</dd>
<dt>Stuart</dt>
<dd> There is a point at which every student learning RDF needs to understand serialization.
</dd>
<dt>Tom</dt>
<dd> At least "a" serialization.
</dd>
<dt>Stuart</dt>
<dd> For example, we may need to see a graph in triples.
</dd>
<dt>Corey</dt>
<dd> Parsing, scripting, grepping. I don't see the distinction between what a programmer or someone else needs to know that is unique -- with regard to basic parsing.
</dd>
<dt>Corey</dt>
<dd> Certain modules need to remain distinct in the tool platform. Tom, yesterday you talked about a shell-based, command-line-interface platform for learning the topics, but I would want it to remain separate from other toolkit resources for those not familiar with the command line.
</dd>
<dt>David</dt>
<dd> How would the tools needed by programmers differ from the tools needed by "conceptual" learners?
</dd>
<dt>Tom</dt>
<dd> You could imagine a Web interface to support the learning of properties, where a command exports the properties you want to, say, a flashcard program.
</dd>
<dt>Ed</dt>
<dd> Don't both emphasize understanding?
</dd>
<dt>Mike</dt>
<dd> <i><b>To make distinctions between different levels of tools, "Beginning, intermediate, and advanced" (talked about earlier) could be brought into this.</b></i>
</dd>
<dt>Diane</dt>
<dd> It's only advanced at a certain level. If you can get it into a spreadsheet or statistical modeling software it becomes a difference of tools, depending on the audience.
</dd>
<dt>Tom</dt>
<dd> What do we put under "Programming"?
</dd>
<dt>David</dt>
<dd> We could make more specific categories under "Programming" rather than moving concepts around needlessly.
</dd>
<dt>Diane</dt>
<dd> What about Quality Control?
</dd>
<dt>Joseph</dt>
<dd> I like Assessment.
</dd>
<dt>Corey</dt>
<dd> I also like Assessment.
</dd>
<dt>Karen</dt>
<dd> We think that the difference between merging and linking triples is an important concept.
</dd>
<dt>Ed</dt>
<dd> Linking is definitely more than reading.
</dd>
<dt>Stuart</dt>
<dd> Two bullets: how do link triples? How do you merge triples?
</dd>
<dt>Karen</dt>
<dd> Open world assumption and closed world assumption
</dd>
<dt>Diane</dt>
<dd> You have to meet people where they are; confront how they see the world is very important. Start with librarians' current understanding of encodings (MARC in their ILS), help them get the concept of encoding through something that is familiar to them.
</dd>
<dt>Stuart</dt>
<dd> <i><b>Most of the people in the world are coming from a world with closed world systems. It permeates what they do. As a core understanding of RDF Linked Data, the open world assumption is fundamental.</b></i> We move people into an in-between state. You can't use a tool if you don't understand it.
</dd>
<dt>Karen</dt>
<dd> You can't talk about triples without talking about what they are: URIs, nodes. What are the elements of triples? Properties and classes is a big one, should have its own category. Knowing the difference between properties and classes is very important. RDF and OWL need to be introduced somewhere, their role in the world.
</dd>
<dt>Tom</dt>
<dd> Inferencing?
</dd>
<dt>Karen</dt>
<dd> Triples and graphs.
</dd>
<dt>Ed</dt>
<dd> What are triples and graphs is a good question.
</dd>
<dt>Marcia</dt>
<dd> What do you mean by Inferencing?
</dd>
<dt>Tom</dt>
<dd> Generating additional information based on the information we already have.
</dd>
<dt>Diane</dt>
<dd> Explanation first, then the how-to.
</dd>
<dt>Stuart</dt>
<dd> The question is whether it is a core part of understanding RDF in order to function. Understanding the landscape is: RDF, RDFS... OWL...
</dd>
<dt>Marcia</dt>
<dd> Ontologies are more fundamental than understanding OWL as a language.
</dd>
<dt>Stuart</dt>
<dd> In the beginning is RDF, then we give it more power (e.g. OWL).
</dd>
<dt>Diane</dt>
<dd> Differentiating between "what" and "how-to" is important. "What OWL is" needs to be understood, but writing OWL may be beyond the scope of the toolkit.
</dd>
<dt>Karen</dt>
<dd> People will be creating OWL whether they like it or not, so I don't think it's out of scope.
</dd>
<dt>Diane</dt>
<dd> Using OWL is very useful but not necessarily using it raw.
</dd>
<dt>Stuart</dt>
<dd> RDFS is quite compact. My students can't get by without understanding RDFS.
</dd>
<dt>Joseph T</dt>
<dd> Understanding the core concept of how inferencing works is important.
</dd>
<dt>Ed</dt>
<dd> What is a vocabulary? As a student, how do I discover new vocabularies?
</dd>
<dt>Diane</dt>
<dd> MARC, RDA, etc.
</dd>
<dt>Marcia</dt>
<dd> Our project is looking at unfamiliar vocabularies. Librarians are great at MARC. Not aware of a music ontology that can link them to the BBC's music dataset.
</dd>
<dt>Stuart</dt>
<dd> There are starter vocabularies. But we should include the others. All of them.
</dd>
<dt>Joseph</dt>
<dd> There's a reason we are listing DC and FOAF, because a lot of people use them. Maybe not the music ontology or others.
</dd>
<dt>Stuart</dt>
<dd> Starters and "non-starters" (extensions?)
</dd>
<dt>Karen</dt>
<dd> The problem I have with the word "vocabulary" is it covers a wide range. Value vocabularies
</dd>
<dt>Tom</dt>
<dd> We need to distinguish between dataset and vocabularies
</dd>
<dt>Marjorie</dt>
<dd> "Vocabulary" is not a clear distinction. Librarians working with "vocabularies" can become very confused.
</dd>
<dt>Tom</dt>
<dd> This was a big topic in the Library Linked Data Incubator Group.
</dd>
<dt>Karen</dt>
<dd> A value vocabulary cannot be a subject or a predicate.
</dd>
<dt>Marcia</dt>
<dd> We decided to use "element sets" and "value vocabularies" instead of just "vocabularies".
</dd>
<dt>Tom</dt>
<dd> I propose we use the definitions from the Incubator Group.
</dd>
</dl>

### Resuming at 10:15 AM 
<dl>
<dt>Tom</dt>
<dd> I think we've made good progress. We should be able to move more quickly now.
</dd>
</dl>


Let's move onto implementation syntax. Also, the new category "Programming." You need to understand triples in graphic form, in one of the syntaxes, or predicate-verb-subject. The question for me is where do we want to put implementation syntax? Karen did you do anything with this in your list?

<dl>
<dt>Karen C</dt>
<dd> It's the same.
</dd>
<dt>Stuart</dt>
<dd> <i><b>If you look at the RDF documentation, you must keep a distinction between RDF (the model) and RDF/XML (the concrete syntax), otherwise students think RDF is just another flavor/variation of XML.</b></i>
</dd>
<dt>Karen</dt>
<dd> I think that translation is part of that.
</dd>
<dt>Tom</dt>
<dd> So translation isn't composing?
</dd>
<dt>Karen</dt>
<dd> I wouldn't usually translate one to another while I'm composing.
</dd>
<dt>Marcia</dt>
<dd> When we talk about triples we need some kind of syntax.
</dd>
<dt>Stuart</dt>
<dd> Is serialization of the graph the same as translation?
</dd>
<dt>Corey</dt>
<dd> Translation is more manipulative.
</dd>
<dt>Karen</dt>
<dd> Going from RDF/XML to N-Triples to Turtle.
</dd>
<dt>Stuart</dt>
<dd> <i><b>RDF is not the syntax. The graph is crucial to understand.</b></i>
</dd>
<dt>Tom</dt>
<dd> We have this notion of "graphic graphs"
</dd>
<dt>Ed</dt>
<dd> For me, talking about triples outside of the context of the graph doesn't make any sense.
</dd>
<dt>Diane</dt>
<dd> It's more a question of representation.
</dd>
<dt>Tom</dt>
<dd> Let's look at the visualization category.
</dd>
<dt>Marcia</dt>
<dd> Are you visualizing relationships between data or elements?
</dd>
<dt>Joe</dt>
<dd> You visualize for a purpose. The reason we visualize is to analyze the data.
</dd>
<dt>Tom</dt>
<dd> Are you saying visualization is not an end in itself?
</dd>
<dt>Joe</dt>
<dd> If the practice in Linked Data is to know what kind and how good your data is, you're going to use visualization as a tool to determine that.
</dd>
<dt>Craig</dt>
<dd> <i><b>It's not sufficient to just say Visualization is just a tool. It is a Topic.</b></i>
</dd>
<dt>Tom</dt>
<dd> <b><i>Visualization is another mode RDF can be expressed in (like reading and writing a language). Hence, it has its own category.</i></b>
</dd>
</dl>


Is anyone suggesting this not be a separate category?

<dl>
<dt>Karen</dt>
<dd> Ontologies and data. Somehow those need to be made into different things. Visualization of each is for differing purposes.
</dd>
<dt>Marcia</dt>
<dd> <i><b>Visualization of models and visualization of data should be distinguished.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Ontologies _are_ data.</b></i>
</dd>
<dt>Karen</dt>
<dd> <i><b>I don't think that's helpful.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>The tools we use to visualize instance data are also just as useful in visualizing the ontologies.</b></i>
</dd>
<dt>Karen</dt>
<dd> I think there are some tools you can use for both, but not all.
</dd>
<dt>Diane</dt>
<dd> You can see anomalies in the structure and how it is populated and you can also see the values. You can tell by looking at a particular element.
</dd>
<dt>Tom</dt>
<dd> Where would we like to introduce a distinction between data and ontologies/vocabularies?
</dd>
<dt>Karen</dt>
<dd> "Composing."
</dd>
<dt>Tom</dt>
<dd> I'm confused because you have vocabulary under "Reading."
</dd>
<dt>Stuart</dt>
<dd> <i><b>Data and attribute spaces are all expressed in the same language. A schema is data.</b></i>
</dd>
<dt>Marcia</dt>
<dd> Data and relationships.
</dd>
</dl>

### Querying 
<dl>
<dt>Tom</dt>
<dd> Querying languages, such as SPARQL...
</dd>
<dt>Corey</dt>
<dd> <i><b>There are no adequate GUIs for constructing SPARQL queries.</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>We're using querying here in a pretty specific sense and general use.</b></i>
</dd>
<dt>Karen</dt>
<dd> <i><b>What's the general sense?</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>Exploring the data.</b></i>
</dd>
<dt>Karen</dt>
<dd> There are Semantic Web search engines.
</dd>
<dt>Corey</dt>
<dd> Do we want this tool environment to include a bibliography with our toolkit?
</dd>
<dt>Craig</dt>
<dd> We shouldn't just stop at the SPARQL query box. There are more ways of approaching a query. We need a general concept of querying and then a specific elaboration on SPARQL.
</dd>
<dt>Tom</dt>
<dd> In a very general sense, one is "asking questions".
</dd>
<dt>Diane</dt>
<dd> Or searching.
</dd>
<dt>Tom</dt>
<dd> <i><b>Let's reflect a broader sense of querying.</b></i>
</dd>
<dt>Diane</dt>
<dd> There seems to be value to merging the concepts.
</dd>
<dt>Karen</dt>
<dd> What about a keyword search?
</dd>
<dt>Karen W.</dt>
<dd> <i><b>"What are the kinds of questions you can ask of a dataset?"</b></i>
</dd>
<dt>Tom</dt>
<dd> That's what I had.
</dd>
<dt>David</dt>
<dd> If you have a general term, like "Inspection" as a starting point.
</dd>
<dt>Joe</dt>
<dd> Searching is an unspoken assumption.
</dd>
<dt>Karen</dt>
<dd> Perhaps, what is out of scope is a Google for Linked Data. A non-development interface for querying.
</dd>
</dl>

### Composing 
<dl>
<dt>Tom</dt>
<dd> Starting with translation.
</dd>
<dt>Karen</dt>
<dd> Can we define that?
</dd>
<dt>Karen</dt>
<dd> Translation is non-RDF to RDF.
</dd>
<dt>Tom</dt>
<dd> Microdata, microformats, RDFa. Transforming data versus making a selection, using XSLT.
</dd>
<dt>Diane</dt>
<dd> I'm still not sure how we're making distinctions. Translation vs. transformation; improving versus changing values (literals to URIs); if transformation is done under the covers it is hard to determine provenance later on.
</dd>
<dt>Mike</dt>
<dd> Maybe it's a higher-level category.
</dd>
<dt>Tom</dt>
<dd> How about I create a new top level category? (Under "Composing", we split out "Transformation" from "Translation".)
</dd>
<dt>David</dt>
<dd> Would the tools be the same for translation and transformation?
</dd>
<dt>Corey</dt>
<dd> <i><b>We often acknowledge that transformation can include loss.</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>Greater complexity to lesser complexity is lossy.</b></i>
</dd>
<dt>Tom</dt>
<dd> in Transforming: Changing versus Selecting.
</dd>
<dt>Diane</dt>
<dd> What about provenance?
</dd>
<dt>Ed</dt>
<dd> It's implicit in RDF.
</dd>
<dt>Joseph T</dt>
<dd> It's a big problem.
</dd>
<dt>Tom</dt>
<dd> Extracting triples from microdata.
</dd>
<dt>Corey</dt>
<dd> [Structured Data Litter?] is really good for that.
</dd>
<dt>Karen</dt>
<dd> Where do we mint URIs in that process?
</dd>
<dt>David</dt>
<dd> At the "Reading" level.
</dd>
<dt>Karen</dt>
<dd> They need to understand them there, but now they need to mint them.
</dd>
<dt>Stuart</dt>
<dd> They need to know the mechanics of creating a namespace (in the context of minting URIs).
</dd>
<dt>Tom</dt>
<dd> Minting URIs should be under "Composing" somewhere.
</dd>
<dt>Joe</dt>
<dd> I should be able to make an assertion with the existing tools: "this is a cat".
</dd>
<dt>Ed</dt>
<dd> We could use the Metadata Registry, which Diane has contributed to.
</dd>
<dt>Joe</dt>
<dd> RDF can be used to create element sets, but that's not its only purpose. 
</dd>
</dl>

### Native RDF terminology versus library-world terminology 
<dl>
<dt>Karen</dt>
<dd> We should bring those terminologies together. Speak librarians' current language.
</dd>
<dt>Stuart</dt>
<dd> There's a difference between making distinctions and not using the common terminology for RDF.
</dd>
<dt>Mike</dt>
<dd> <i><b>We should include the synonyms, as Craig has suggested, of how other communities/domains discuss these topics.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>If the educational goal is to take the library community from a certain point. If we don't tie them into the language of RDF they'll be needing training and orientation more often.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>It would be useful for readers to have these rough handles. Anyone think we should drop any of these after this discussion?</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>RDF is what it is. Explain it. Then shape it in a learning environment for librarians to understand.</b></i>
</dd>
<dt>Corey</dt>
<dd> As a sort of mapping. <i><b>Start with RDF vocabularies and then explain to them how they relate to librarianship.</b></i>
</dd>
<dt>Mike</dt>
<dd> <i><b>Until we get to a neutral point of language the communities will talk over each other.</b></i>
</dd>
<dt>Joe</dt>
<dd> Is linked data the conversion of concepts to triples?
</dd>
<dt>Stuart</dt>
<dd> <i><b>We do have this grant, from IMLS, but ground it in the domain (RDF), and then to secure the deployment of something, we address the audience of the tools.</b></i>
</dd>
<dt>David</dt>
<dd> Librarians should be instructed in understanding how to talk about authority control (for example) with developers operating in a more general space.
</dd>
<dt>Tom</dt>
<dd> <i><b>Conclusion: This should be written in the idiom of RDF.</b></i>
</dd>
</dl>

### Resume at 1:00 PM 
<dl>
<dt>Tom</dt>
<dd> Agenda for this session: finish the remaining Learning Topics. One big remaining piece: application profile. After the break will look at the entire picture in terms of tools: availability, areas to focus on, overlap. Very end: how to move ahead with next actions: recruiting reviewers, etc. Requesting use cases be written up on the list.
</dd>
</dl>


[<img alt="Singapore Framework" src="/archive/mediawiki_wiki/images/Singapore-framework-newdiagram.jpg" width="924" height="553">](/archive/mediawiki_wiki/images/Singapore-framework-newdiagram.jpg "Singapore Framework")

<dl>
<dt>Tom</dt>
<dd> Corey suggested it's outside the domain of Linked Data in terms of terminology? Data element sets. Data format: expressing a process, interpretable as RDF (uses metadata vocab, existing models in wider community). Used in IMLS grant proposal; not sure it should keep the same form in future grant. Let's get our heads around what it means to compose Linked Data; whether it's helpful to frame in Singapore Framework terms.
</dd>
<dt>Stuart</dt>
<dd> I use Singapore framework as a process model for design. Independent of application profile definition. There is no settled definition, but it means something specific here as distinct from more traditional understandings -- e.g., XML and prior (MARC, etc.). We must draw distinction between traditional notions and what it means here. What does it mean here? Rachel Heery's definition -- mixing and matching from multiple namespaces?
</dd>
<dt>Tom</dt>
<dd> Basically, yes -- mixed RDF vocabulary. Involves design of metadata that uses RDF vocabulary and doesn't necessarily express the metadata in an RDF serialization. <i><b>Creating a non-RDF data format straightforwardly expressible as triples.</b></i>
</dd>
<dt>Stuart</dt>
<dd> Traditionally deals with picking and choosing. We start with mixing of namespaces, which is the core. Creating a higher-level schema which says: "In this application, use these from here; these from here."
</dd>
<dt>Corey</dt>
<dd> To what end? Application more about taking triple-soup you use to build RDF graphs and frame it as an XML record-like thing for use by particular systems.
</dd>
<dt>Karen C</dt>
<dd> Does it necessarily imply constraints?
</dd>
<dt>Stuart</dt>
<dd> Before we move on, the idea of mixing namespaces is inherent in RDF. The constraints around it shape a record or view.
</dd>
<dt>Corey</dt>
<dd> I've never understood why we've put those constraints as part of RDF model. If you use XML you can use XML schema declarations. It bridges to the "record" model and allows you to build representations.
</dd>
<dt>Diane</dt>
<dd> You can validate, use application profiles on the way in and out.
</dd>
<dt>Corey</dt>
<dd> But that's about consuming or producing XML, etc. -- not necessarily an RDF-based view.
</dd>
<dt>Stuart</dt>
<dd> I'm prepping a class. In about Week Eight we'll do application profiles. We've gone through a lot that's up here. We get to application profiles, and I look back at every example from Day One of class, and they've been mixing. What do I have left to say?
</dd>
<dt>Corey</dt>
<dd> <i><b>A use case at NYU: MARC, EAC, Dublin core, "NYU core" records. To combine, first I need to set ability to combine by disaggregating. SOLR-based indexing: I need a new set of rules for picking which pieces go into record. Five records, merged into graph, turned into a single record. There's a huge use case for that.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>What's in the middle is the application profile.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Isn't the application profile just the target you're mapping to?</b></i>
</dd>
<dt>Corey</dt>
<dd> I'm pulling from applications with profiles that correspond with data going in other direction.
</dd>
<dt>Diane</dt>
<dd> Two views of application profile movement: process, building documentation. In some respects what you have in an application profile is an expression of intention. A way to, in an increasingly chaotic world, give surety that something will be what you think. Process of coming to consensus, making specific, functional requirements, etc. That's just the beginning. The piece that's hard right now is when you have some technical framework in which to express, and a way to share outside of one institution. That's the piece that isn't there yet. The process part is still extremely useful to ensure predictability, quality of what's going in and out. Link what you're doing to what you think you're doing.
</dd>
<dt>Stuart</dt>
<dd> But I know what students will ask: "What is it?"
</dd>
<dt>Karen</dt>
<dd> And how do I make one?
</dd>
<dt>Stuart</dt>
<dd> There's an "it" there.
</dd>
<dt>Diane</dt>
<dd> A fuller documentation model a valuable.
</dd>
<dt>Stuart</dt>
<dd> First stages in Dublin Core: very attractive tables. Also, expressing how it's going to be used.
</dd>
<dt>Diane</dt>
<dd> Setting expectations.
</dd>
<dt>Karen C</dt>
<dd> But that's in language, not code.
</dd>
<dt>Craig</dt>
<dd> How it's interpreted within that system. It's implemented in code, but we won't see it. Bringing things together is its intent, but it doesn't allow you to draw a box. There is no formal syntax to describe that.
</dd>
<dt>Corey</dt>
<dd> How various triples relate to facet groups when you search. Can you have more than one entry in a particular thing that generates a facet? Or is that facet grouping saying a single thing about the resource? 
</dd>
<dt>Tom</dt>
<dd> I think we need to see this in light of this particular project, of learning linked data. What an application profile produces needs to be Linked Data (in this context).
</dd>
<dt>Diane</dt>
<dd> Or it can be translated or transformed, can be a precursor.
</dd>
<dt>Tom</dt>
<dd> <i><b>How far back do we go from Linked Data itself to metadata design that is compatible with Linked Data? That's the scoping question. It raises the bar to say, "We're going to encompass use cases" like the one Corey mentioned, taking a number of XML representation and normalizing to another XML representation. One is taking another step away from Linked Data.</b></i>
</dd>
<dt>Corey</dt>
<dd> It does have to be out of scope for grant; no guarantee that during this timeline functional specifications will be finished, let alone how to teach.  
</dd>
<dt>Stuart</dt>
<dd> A lot of ways to do mechanisms.
</dd>
<dt>Tom</dt>
<dd> <i><b>I'd love to have a toolset for application profiles but worry about scope creep.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Let me throw out an assertion that it doesn't belong here. If you open the door beyond multiple namespaces, it gets very complex very quickly and someone who doesn't know RDF will be blown away. Maybe it is too soon to be thinking about it.</b></i>
</dd>
<dt>Marcia</dt>
<dd> <i><b>Based on teaching, European projects: modeling is very important. Singapore framework is one way to approach it, but not the only one. It brings a few additional things they have to figure out. Some people already know UML or databases very well.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Just look at the top layer. It gives you four steps to principled design -- whether you do it in RDF or not.</b></i>
</dd>
<dt>Marcia</dt>
<dd> <i><b>The first two boxes and the next two on the second line are the ones we generally have agreement on; easier to teach and communicate without knowing the rest.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>I structure a class using just this top layer. Anyway, I posit it's too much.</b></i>
</dd>
<dt>David</dt>
<dd> The terminology is a barrier in itself. If it can be talked about in more functional terms -- what's a Domain Model? -- it's more useful for students. To complete an application profile you'll have to do all those steps, whatever they're called. The important thing is to do the steps. And figure out how to describe it to the learner.
</dd>
<dt>Joseph B</dt>
<dd> The application profile as a documentation of all these things seems important. In a tool, you want to call out -- we don't know exactly what it's going to be, but you want to have a way for the tool to prompt you, help you.
</dd>
<dt>Stuart</dt>
<dd> Historically, application profiles in DCMI were that -- documenting constraints for a given context. Then we moved onto the goal of making it machine-expressible, operable. There's the complexity.
</dd>
<dt>Tom</dt>
<dd> The other intention here is that DCAM came out of trying to bridge the gap between RDF and XML mindsets. The description set is an abstract way to say, "What's a record? In Linked Data world, you don't have to think in terms of records; you look for patterns that match the triple soup. Other ways of conceptualizing don't involve the notion of a record in the forefront.
</dd>
<dt>Karen C</dt>
<dd> I have a question about applications. Everything we have here is about working with RDF, we get to publishing and storing. Application is another leap from this. Will that be part of this training?
</dd>
<dt>Joseph B</dt>
<dd> The important part is thinking about creating the application, not actually creating it.  
</dd>
<dt>Stuart</dt>
<dd> People create data within a constrained context (typing into fields). The notion of documentation around what will appear on the screen. Application profile also controls the environment in which data is created, entered.
</dd>
<dt>Karen C</dt>
<dd> I'm questioning whether that's part of this, and where it comes in. I don't see it as a separate thing.
</dd>
<dt>Joseph B</dt>
<dd> What if it's called application profile documentation instead of design?
</dd>
<dt>Karen C</dt>
<dd> I'm not sure that's what people are thinking about.
</dd>
<dt>Stuart</dt>
<dd> Documentation is constraint. Singapore Framework describes guidelines as things not enforceable through the framework.
</dd>
<dt>Karen C</dt>
<dd> I don't think it's only things that are not enforceable -- that's why they are in language instead of code.
</dd>
<dt>Mike</dt>
<dd> <i><b>Are we taking a use case into the idea of what we need to do with Linked Data? Corey, Stuart's examples. Maybe that's where the application profile part goes (not here).</b></i>
</dd>
<dt>Corey</dt>
<dd> Another thing that makes me think this is out of scope is Pellet and Michael Panzer's Pittsburgh presentation about using OWL as a closed-world constraint language. Making a closed system, tells you whether your metadata matches an ontology. We decided advanced ontology construction is beyond the scope of the Learning Linked Data project. This is about learning the principles of RDF. When we were talking about taking non-RDF Linked Data out of scope, these principles inform good metadata practice. Helps with naming and creating relationships.
</dd>
<dt>Diane</dt>
<dd> Allows you to be in the open world with triples and figure out how to use them in reality, in an environment that needs some constraints to operate. That sort of thing, even as we declare it out of scope we need to point people towards it as something to think about.
</dd>
<dt>Stuart</dt>
<dd> Everything that ends up on the board is fundamental to a holistic learning environment.
</dd>
<dt>Tom</dt>
<dd> I think we're converging on calling an application profile, per se, out of scope, but some pieces of the application profile may be in scope.
</dd>
</dl>

#### Domain Model? 
<dl>
<dt>Karen C</dt>
<dd> I would move it up into "Understanding." One thing I thought was missing was entities and relationships, which is really what your domain model is.
</dd>
<dt>Corey</dt>
<dd> <i><b>The domain model is the beginning of taking an open world and constraining it; I almost want to pull all of that out of scope.</b></i>
</dd>
<dt>Karen C</dt>
<dd> <i><b>I don't see how people can compose anything without a domain model.</b></i>
</dd>
<dt>Marcia</dt>
<dd> <i><b>I agree; it's a very basic communication tool so that people know what you're talking about.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>It's the first level of constraints on everything in the world; filters out what you're not going to be dealing with.</b></i>
</dd>
<dt>Diane</dt>
<dd> Are you talking about domain model outside the framework, as a given?
</dd>
<dt>Stuart</dt>
<dd> No. <i><b>All of this is a set of constraints. This is the first: "What am I talking about?"</b></i>
</dd>
<dt>Tom</dt>
<dd> What if we took design of languages of description, elevated it to a heading. 
</dd>
<dt>Craig</dt>
<dd> I would feel better. An application profile in RDF-land is just another vocabulary, or I'll use ontology loosely, it's pulling references from namespaces to validate against, proposing something new from other stuff. 
</dd>
<dt>Stuart</dt>
<dd> That's the problem with my students. We've already done it. But the Domain model at the beginning of the processes gives you a universe to describe.
</dd>
<dt>Diane</dt>
<dd> Seems to me the distinction we've been trying to make is, when pulling out design issues or ontology issues as out of scope, if you're talking about a domain model as something divorced from that process, something you were given, etc.
</dd>
<dt>Stuart</dt>
<dd> Whether I'm given it or create it, it's necessary.
</dd>
<dt>Diane</dt>
<dd> But if we want to stay out of the design piece...
</dd>
<dt>Mike</dt>
<dd> <i><b>Stuart, isn't that still part of the use case, that you're using this tool to help you teach?</b></i>
</dd>
<dt>Stuart</dt>
<dd> Yes, but it's not in the conceptual foundation of RDF itself. However, I have trouble seeing how I'd talk to anyone about it. I see what you're saying.
</dd>
<dt>Mike</dt>
<dd> Ways to put domain models into the underpinnings of what will happen when you try these tools. 
</dd>
<dt>Karen C</dt>
<dd> One test could be, if there's anything else on there you couldn't do if you didn't have a domain model. Could you create, compose, etc.?
</dd>
<dt>Ed</dt>
<dd> The domain model would be implicit in what you're publishing. 
</dd>
<dt>Joseph T</dt>
<dd> But we're retrofitting data all the time. If we reduce Linked Data to that which is publishable and shareable on the web, what's the domain model from that? If we're describing a process of discovery -- i.e., My Life Bits -- if it's Linked Data, it will just be assertions about these resources at particular points in time. 
</dd>
<dt>Ed</dt>
<dd> It doesn't have to be exhaustive, fully formed, but you have to have some notion of what you're doing.
</dd>
<dt>Joseph T</dt>
<dd> Designing good metadata for retrieval and display, yes. Good vs. bad metadata.
</dd>
<dt>Tom</dt>
<dd> I'd like to pick up on that. We've already said that creating element sets (data entities that are commonly being used as properties) and value vocabularies (entities that are being used as values). We want those to be in scope; are domain models different? Would we feel comfortable moving this block under a heading "Designing languages of description," and adding Domain model?
</dd>
<dt>Karen C</dt>
<dd> Put Domain Models first.
</dd>
<dt>Ed</dt>
<dd> <i><b>"Designing languages of description" sounds hard.</b></i>
</dd>
<dt>Stuart</dt>
<dd> '<i><b>But that's what you're doing.</b></i>
</dd>
<dt>Karen W</dt>
<dd> <i><b>Don't tell them!</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>It doesn't make for an attractive job description.</b></i>
</dd>
<dt>Craig</dt>
<dd> <i><b>From a systems design perspective, "domain model" is related to data model. I would call those data models, but that's really overloading something that would confuse me as a student. At least "Language of Description" shows it's not a data model in the traditional sense.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>But "Language of Description" fits with the theme.</b></i>
</dd>
<dt>Craig</dt>
<dd> <i><b>Maybe different fields have different understandings of these types of models.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>The language metaphor, in this context, is apt.</b></i>
</dd>
<dt>Craig</dt>
<dd> <i><b>It's just as apt to describe symbolic languages, which you would never try to bridge over to natural languages. It's a hard thing to market. It doesn't reach me as an audience.</b></i>
</dd>
<dt>Mike</dt>
<dd> <i><b>We're back to the conversation about Element Sets. It goes back to expressing it in difference ways. We need different ways to call the same thing.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>When you go out there looking for tools for Linked Data, they're not going to be speaking in terms of linguistics. You're going to need something to connect it together; you're introducing dissonance by talking about it in a way that doesn't match the tools.</b></i>
</dd>
<dt>Tom</dt>
<dd> It's up to the instructor to present it in a way that makes sense.
</dd>
<dt>Corey</dt>
<dd> We agreed at the beginning of yesterday to keep pedagogically specific things out of scope.
</dd>
<dt>Stuart</dt>
<dd> <i><b>"Designing an RDF Vocabulary"?</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>An RDF vocabulary, from a formal point of view, is a data set. A SKOS concept scheme, I'm sorry to say, is also a data set.</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>"Designing RDF Vocabularies and Data Sets"?</b></i>
</dd>
<dt>Karen C</dt>
<dd> <i><b>Isn't RDF the language?</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>RDF is the grammar, and it provides some vocabulary.</b></i>
</dd>
<dt>Joseph T</dt>
<dd> But zero semantics; RDF is the container. We have to imbue it with meaning; RDF is metadata about metadata, yes?
</dd>
<dt>Stuart</dt>
<dd> <i><b>I don't think it's a big issue; we'll have to do more explanation around "Vocabulary" and understand it's loaded.</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>Grounding it in RDF allows instructors to use whatever metaphor or mechanism makes sense to them and their students -- linguistics, math, logic...</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>This is a document about RDF, so we should stick with RDF wherever RDF has a term that is commonly used.</b></i>
</dd>
<dt>Diane</dt>
<dd> Those who are using this to build courses or workshops will be putting that gloss on that for their students' particular situation.
</dd>
<dt>Mike</dt>
<dd> We can refine it further.
</dd>
<dt>Tom</dt>
<dd> Ok, "Prototype Application"... -- does anyone want to keep that in? <i><b>Singapore Framework -- gone?</b></i>
</dd>
<dt>Diane</dt>
<dd> We don't want to lose those. Maybe point to them?
</dd>
<dt>Corey</dt>
<dd> <i><b>Singapore Framework has nothing to do with RDF per se. It's a layer on top that helps a particular group understand how it applies to them, but that's not what we're teaching.</b></i>
</dd>
<dt>Tom</dt>
<dd> So we have three headings: Simple Composition, Designing RDF Vocabularies, and Linking. We have two more to get done before 3:00.
</dd>
</dl>

#### Publishing... 
<dl>
<dt>Marcia</dt>
<dd> Publish on the Web has two different meanings.
</dd>
<dt>Mike</dt>
<dd> Making it accessible versus giving someone the entire set.
</dd>
<dt>Craig</dt>
<dd> '<b>If you just took your data, put it in a .ZIP file and put it out there, it's not Linked Data in the traditional sense of linking to anything. We're really talking about the idea of exposing a universal URI.</b>
</dd>
<dt>Marcia</dt>
<dd> <i><b>LCSH vs. providing different formats for downloading everything, or just pieces. For DDC you can only link, not download everything. The availability is different.</b></i>
</dd>
<dt>Tom</dt>
<dd> That seems to point in the direction of intellectual property issues and whether something is published as "open" Linked Data. In terms of a learning platform, the goal should be simple.
</dd>
<dt>Diane</dt>
<dd> But you have to explain what publishing means in this context. Plenty of people think it means uploading a PDF; in terms of its usability...
</dd>
<dt>Tom</dt>
<dd> <i><b>So "Publishing Linked Data as Linked Data"?</b></i>
</dd>
<dt>Karen C</dt>
<dd> <i><b>If you don't have de-referenceable URIs it's not Linked Data.</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>But you can put URIs into a PDF.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>You can have Linked Data that uses non-de-reference-able URIs -- e.g., info URIs.</b></i>
</dd>
<dt>Marcia</dt>
<dd> Data that is displayed as human-readable on the Web is not the same data you download to use for your system.
</dd>
<dt>Craig</dt>
<dd> Is the goal for me to learn how to publish the full set to the web, or is it for me to publish Linked Data as Linked Data? Let's cut away the options that aren't the simplest.
</dd>
<dt>Tom</dt>
<dd> Can I use that? Ok: Publishing Linked Data as Linked Data is the new heading.
</dd>
<dt>Ed</dt>
<dd> <i><b>Patterns for minting URLs are a fundamental part of publishing.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Does that belong in Designing RDF Vocabularies?</b></i>
</dd>
<dt>Joseph T</dt>
<dd> Conceptual vs. mechanical; there's an architecture to de-reference. 
</dd>
<dt>Ed</dt>
<dd> <i><b>How you define your resources so other people can use them.</b></i>
</dd>
<dt>Tom</dt>
<dd> If we have Creating RDF Data as the heading, and under that Minting URIs, Creating Domain Models... I'll write something up and we can tear it apart. Ok. Publishing on the Web: Content Negotiation, and Publishing Syntaxes. 
</dd>
<dt>Corey</dt>
<dd> <i><b>Do we have to go into Range 14 and 303s and hash vs. slash URIs in the publishing section? That's part of how RDF works right now. I think we have to cover it.</b></i>
</dd>
<dt>Diane</dt>
<dd> We at least have to acknowledge it.
</dd>
<dt>Tom</dt>
<dd> We have to put it on the list; it doesn't have to be covered in any given course.
</dd>
</dl>

#### Storing... 
<dl>
<dt>Tom</dt>
<dd> Oh, and we have Programming down here...
</dd>
<dt>Corey</dt>
<dd> I suggested it, but <i><b>I'm not sure Programming needs to be part of a separate Learning Topic. There could be "advanced" modules with command-line versions of things covered by non-command-line-interface tools.</b></i>
</dd>
<dt>Diane</dt>
<dd> Is "Storing" in this context limited to triple stores?
</dd>
<dt>Corey</dt>
<dd> <i><b>A lot of real RDF is not stored as triples. People use relational databases, MongoDB.</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>I think it makes sense to talk about "Storing" as a topic, and then different types of storage people are using.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Within the context of teaching, having data available, having students be able to plug into a data store, is important. Accessing and extracting, visualizing.</b></i>
</dd>
<dt>Tom</dt>
<dd> But it's not necessarily something you'd want to have a module about.
</dd>
<dt>Diane</dt>
<dd> Depending on your audience.
</dd>
<dt>Craig</dt>
<dd> <i><b>As a learning topic, the idea that you don't have to store in a triple store is a good point to discuss.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>Particularly on a publishing side. When students go into the world, they'll encounter all types of databases. They can use that structured data and present it as Linked Data on the web, if they know it doesn't have to be stored in only one way. If they're working with RDF data, they don't want to have to get into parsing and loading it into relational databases, MongoDB, etc. Triple storing is easier; it makes sense as a pedagogical tool.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>As a learning tool it should cover that, but as a learning topic should cover different types of storage (including triple store)? Ok. So we need to distinguish between having a Triple Store as a tool platform, vs. triple stores and alternatives as a learning topic. We have two final points: Indexing Triples...we covered that somewhere. Where do we talk about the step between storing and querying? Does that need to be a learning topic, or are we transitioning into the functionalities requirement?</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Why is that more critical than triple stores themselves, talking about how they work?</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>I wonder if the last section should, after all, be "Technical Implementation Details." "Here's the hardcore things you might need to know to do this."</b></i>
</dd>
<dt>Marjorie</dt>
<dd> What if you actually want to do Linked Data? This is where the rubber hits the road. You've learned all this other stuff. So now what?
</dd>
<dt>Stuart</dt>
<dd> Those pieces cover all of the synapses that make it work; they may not be here, but they're actually critical. <i><b>It's weird to lead people to the edge, and then leave them without the ability to actually put it into practice.</b></i> This is where competencies shift.  
</dd>
<dt>Corey</dt>
<dd> This is just for the special cases for the people who care more about the technical side.
</dd>
<dt>Marjorie</dt>
<dd> <i><b>I'd just say "Implementation."</b></i>
</dd>
<dt>Diane</dt>
<dd> Then we can talk about other types of implementation.
</dd>
<dt>Stuart</dt>
<dd> It's a shift in gears. There are all kinds of prerequisites you have to know to understand.
</dd>
<dt>Corey</dt>
<dd> But there are communities where this would be a starting point.
</dd>
<dt>Stuart</dt>
<dd> Different sets of prerequisite knowledge. 
</dd>
</dl>

#### Associating Learning Topics with Tool Categories 
<dl>
<dt>Tom</dt>
<dd> The next step is to try to associate some tool categories with these topics.
</dd>
<dt>Marjorie</dt>
<dd> Would you mind summarizing the whiteboard?
</dd>
<dt>Tom</dt>
<dd> Three broad categories:  
</dd>
</dl>
<pre>Prerequisite competencies
Learning topics (6 high-level categories)  
1. Reading  
   Understanding:  
   RDF Grammar,  
   Vocabulary,  
   RDF Implementaton Syntax 
2. Querying  
3. Composing  
   Simple composition,  
   Designing RDF Vocabularies,    
   Translation,  
   Transformation,  
   Extraction,  
   Linking, 
   Creating RDF Data 
4. Visualization 
5. Publishing Linked Data as Linked Data 
6. Storing [now Implementation] 
Out of Scope 
1. Advanced Ontology and Engineering 
2. User Service Interface 
3. User Application
</pre><dl>
<dt>Karen C</dt>
<dd> How are we going to add the tools to that mess?
</dd>
<dt>Tom</dt>
<dd> We'll use a blue pen for that. We don't want to talk about specific tools, but types of tools -- "exemplars" of tools.
</dd>
</dl>

### Resuming at 3:15 PM 
<dl>
<dt>Diane</dt>
<dd> Will we talk about audience? Personas versus learners; no different training for different levels of engagement.
</dd>
<dt>David</dt>
<dd> Allows you to compare, gives you detail about which aspects might be problems for certain audiences. 
</dd>
<dt>Corey</dt>
<dd> Audiences are abstract classes; personas are exemplars with fake details to fill them out.
</dd>
<dt>Stuart</dt>
<dd> <i><b>If we do our homework on the use cases, we'll be able to fill out details about audience.</b></i>
</dd>
</dl>

### Use Cases 
<dl>
<dt>Tom</dt>
<dd> One of the final things we need to do is clarify the use case assignment. Is everyone clear on what we want?
</dd>
<dt>Joseph B</dt>
<dd> I think we want to talk about it a little bit. I don't do any training around helping people to learn RDF; I help them understand why they should care and how it's interesting. Being able to point to tools to help in learning how to use RDF is important. I have to construct fake use cases; I would go interview you guys to get my use cases. I solve more concrete problems. Linked data might be a solution we come up with as the outcome. I doubt there are many people besides Eric Miller and Tom Baker who are doing consulting projects with organizations around Linked Data. Another example would be Top Quadrant. I don't think organizations have clear use cases. It's usually framed in a much fuzzier way. <i><b>You just crossed out all the things that I do; my use cases are out of scope. Companies want consultants to produce deliverables. What you're doing here is creating an environment for people to teach themselves. A corporate problem would be that they can't efficiently get the data they need because it's dispersed in all these different places. I educate them, get their data management people to stop doing "data management," and think about how their data should be made Linked Data ready without building another system. A lot of this is how to educate people in the real world who are IT professionals, library professionals, to think differently about problems they're already familiar with. This tool is focused on one part of that educational process.</b></i>
</dd>
<dt>Karen C</dt>
<dd> I think Diane and my experience is similar, getting people to wrap their heads around the general concepts. 
</dd>
<dt>Marjorie</dt>
<dd> <i><b>My need would be a little different; I have to deliver the actual product. I might start with specifications, but we have to take data, massage it, and put it into a system where it will work. A science association might have journals, conferences, committees, etc. on a topic. If someone has an article they discovered, they might want to link out to other things in different formats or venues that have to do with that data. The use case is being able to present on a website to the searcher who finds that article the upcoming conference, etc. It's a great use for Linked Data capability. I have two that are fairly well along.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>Or in records management. I have a client that's a large insurance company, with 2 terabytes of undifferentiated data lying around like a bomb. It costs them over a million dollars a year to maintain the drive. The application there is to figure out the retention schedule for the data. We have a controlled vocabulary and a retention schedule, and you link the two and apply it in a crawling mechanism to assign retention schedules to every information object on the shared server. They have legal holds on some data that would otherwise get some of those schedules. Another one is authors. We have a large publisher who wants to make a database of their authors for social interaction, etc. The first step is to disambiguate the authors. Which is the first name, which the last? Is it the same persona? People move around a lot, and do things under different corporate sources. ONIX, which is for book publishers, is taking on a new life in the e-book environment.</b></i>
</dd>
<dt>Joseph B</dt>
<dd> Are these use cases relevant to this grant?
</dd>
<dt>Marjorie</dt>
<dd> <i><b>I envision people who come out of this course working for me with Linked Data, using RDF wrappers.</b></i>
</dd>
<dt>Mike</dt>
<dd> <i><b>I think there is some connection here; I think your [Joseph B's] connection is a little farther away.</b></i>
</dd>
<dt>Craig</dt>
<dd> <i><b>Do you train in the sense of going into the organization and teaching them how to do it?</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>We deliver, and teach them to maintain it.</b></i>
</dd>
<dt>Craig</dt>
<dd> <i><b>I've been through a number of similar trainings as an employee; the tech people don't necessarily already know this stuff.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>It's difficult to find someplace to send people; we end up doing in-house training.</b></i>
</dd>
<dt>David</dt>
<dd> They key is going to be organizations who don't have the money to do this and send someone off to figure it out; there's no solid package of material. Assembling it would save time and be very helpful.
</dd>
<dt>Marcia</dt>
<dd> <i><b>Collecting these use cases could be an important component of the platform; allowing people to match use cases to their own situation.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Especially the ones that have a learning component. If we go down the path of collecting use cases for Linked Data per se, it will be hard to relate to the platform as we're talking about it.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>But you could look at Marjie's cases and say, "What would it take to have someone who could do that?" What are the learning requirements to bring someone like that up to speed? It's fascinating that so much of the Linked Data stuff is about public data opening.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>No; that's just what you're reading about Most of it is buried in government organization, corporations, associations. The heavy duty implementations are much deeper.</b></i>
</dd>
<dt>Stuart</dt>
<dd> It's critical because we're supposed to be educating the people who do this stuff.
</dd>
<dt>Marjorie</dt>
<dd> <i><b>And when someone comes to me and has a Masters of Information-Something, Information Management-something from someplace... employers can't know any more what that means. I have to ask for class syllabi.</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>I think we've done well by focusing on the technologies, the principles. It doesn't make the distinction between enterprise and open environments.</b></i>
</dd>
<dt>Marcia</dt>
<dd> <i><b>I have some use cases of bad data, including a Canadian government agency that who converted data to triples perfectly, called it SKOS, but it was all wrong in the semantics. I have more than one case like that.</b></i>
</dd>
<dt>Ed</dt>
<dd> That gets us back into assessment tools.
</dd>
</dl>

### Tools 
<dl>
<dt>Tom</dt>
<dd> This may be a good time to segue to tools. We want to assign these Learning Topics to generic types of tools.
</dd>
<dt>Ed</dt>
<dd> Do they have to exist?
</dd>
<dt>Tom</dt>
<dd> No, but if they don't we should put an asterisk :-)
</dd>
<dt>Ed</dt>
<dd> If you can't give an example, it doesn't exist.
</dd>
<dt>Karen C</dt>
<dd> In a chapter I recently wrote, I categorized tools as follows: metadata definition and development, list and thesaurus development (SKOS-y things), general programming tools for RDF, viewers of various kinds as visualization tools, converters and validators (may be different, but are often found together); tools for discovery of RDF metadata, services; link creation and term mapping; search tools; and data creation tools. 
</dd>
<dt>Stuart</dt>
<dd> What are "general programming tools"?
</dd>
<dt>Karen C</dt>
<dd> Pellet and various RDF libraries. Triple store tools. Programming environment, Development Environment, Reasoners, RDF generators, converters. [Another site has] Agent systems, annotators, browsers, ontology mappers, frameworks, parsers, query language, database data store, inference engine SPARQL, visualization. These are all linked to my wiki.
</dd>
<dt>Corey</dt>
<dd> The W3C web also has a list of lists of tools.
</dd>
<dt>Tom</dt>
<dd> Let's walk through the topics.
</dd>
<dt>Corey</dt>
<dd> LOD-2 stack: a disk image, a fork of Ubuntu, the OS. It comes with a lot of Semantic Web tools -- e.g., Virtuoso as a triple store and data management environment.
</dd>
<dt>Craig</dt>
<dd> Web information quality assessment framework. Virtuoso.
</dd>
<dt>Corey</dt>
<dd> Sindice is an indexing tool; separate from storage.
</dd>
<dt>Tom</dt>
<dd> In the next hour and ten minutes, associate types of tools needed in each of these categories. <i><b>Starting with RDF Grammar; we weren't sure that all of these need tools, some might be conceptual. For the grammar we have property-class instance graphs, triples, merging triples, linking graphs, open/closed world assumption, assessment...</b></i>
</dd>
<dt>Karen C</dt>
<dd> <i><b>These are about understanding those concepts, not doing the activity, right?</b></i>
</dd>
<dt>Tom</dt>
<dd> That's the question.
</dd>
<dt>Stuart</dt>
<dd> Being able to demo that for a class, though...
</dd>
<dt>Craig</dt>
<dd> A lot of these support visualization or composition.
</dd>
<dt>Tom</dt>
<dd> Maybe the tools come in later, but there's a "demo platform" of basics.
</dd>
<dt>Stuart</dt>
<dd> <i><b>I would imagine someone putting together a tutorial or class would deploy those to illustrate. I don't know if they would be different than the tools up there. I don't think you need a "demo" tool per se. Create a demo using these tools.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>Maybe we start populating tools out here, in the doing end as opposed to the knowing end. Ok, so inference name graphs, assessment.</b></i>
</dd>
<dt>Karen C</dt>
<dd> That's still in knowing.
</dd>
</dl>

### Composiing (creating data) 
<dl>
<dt>Stuart</dt>
<dd> Start with composing. "In the beginning, there was the creation."
</dd>
</dl>
<dl>
<dt>Tom</dt>
<dd> Let's start with Simple composition, Designing RDF Vocabularies, Creating RDF Data [is designing vocabulary now under creating data?] [general outline confusion]
</dd>
<dt>Karen C</dt>
<dd> We're creating the data not the ontologies, yes?
</dd>
<dt>Ed</dt>
<dd> We have list and thesaurus development up there. Metadata registry.
</dd>
<dt>Stuart</dt>
<dd> I would say you need an editor; you may be teaching SKOS at the level of angle brackets.
</dd>
<dt>Ed</dt>
<dd> In that case, a turtle parser is almost a tool.
</dd>
<dt>Stuart</dt>
<dd> We've got serializations. If you've got a schema, you've got to write it out somehow.
</dd>
<dt>Karen C</dt>
<dd> It's nice to have a programming-friendly editor.
</dd>
<dt>Tom</dt>
<dd> How about concept scheme and ontology editor as a category?
</dd>
<dt>Diane</dt>
<dd> But I don't seem to be hearing that we're talking about more than one audience.
</dd>
<dt>Stuart</dt>
<dd> But you are, when you're talking about NotePad up through Oxygen.
</dd>
<dt>Tom</dt>
<dd> So we're talking about data creation tools, data editors (if that's the right term), concept scheme/ontology editors...
</dd>
<dt>Joseph T</dt>
<dd> RDF vocabulary editors?
</dd>
<dt>Tom</dt>
<dd> Ok. And SKOS?
</dd>
<dt>Corey</dt>
<dd> It's a data set.
</dd>
<dt>Tom</dt>
<dd> So, data editor?
</dd>
<dt>Corey</dt>
<dd> It depends how you want to define it. Deployers will need to be able to, i.e., work with Apache, understand 303 redirects, etc. I think from the implementation details end...
</dd>
<dt>Tom</dt>
<dd> I'm going to fill in some gaps. What did you just mention? Web servers.
</dd>
<dt>Ed</dt>
<dd> <i><b>This might be out of scope, but Web frameworks?</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>There's also content management systems like Drupal.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>That crosses over that skill-set line, again.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>So maybe we should start putting some tools in the out-of-scope area.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>It's hard to think about publishing on the Web without that, because that's what publishing on the Web is.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>How would you describe Web frameworks?</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>Like Ruby on Rails, Zen framework for PHP: software libraries that help you publish on the Web.</b></i>
</dd>
<dt>Craig</dt>
<dd> On the far right...creating name models? I would see a data modeling tool as something different than vocabulary. They might be integrated, but...
</dd>
<dt>Diane</dt>
<dd> Some of the diagramming tools have UML templates.
</dd>
<dt>Craig</dt>
<dd> There are ER tools that create tables and databases -- code generating stuff -- or sometimes you just design something in Visio.
</dd>
<dt>Tom</dt>
<dd> Ok, linking. Creating and discovering relationships.
</dd>
<dt>Karen C</dt>
<dd> There are things that help you create links and map terms.
</dd>
</dl>

### Mapping tools 
<dl>
<dt>Stuart</dt>
<dd> Mapping tools?
</dd>
<dt>Tom</dt>
<dd> <i><b>So, tools that support the process of discovering things to link?</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>They assume the presence of two nodes and the ability to create a link for them.</b></i>
</dd>
<dt>Karen C</dt>
<dd> You have two different sets, you plug them in, and you draw relationships. Some of those tools are translation tools; it will try to assign it a URI.
</dd>
<dt>Ed</dt>
<dd> <i><b>Calais for example, you throw text at it and it returns linked data. I think of that as more extraction.</b></i>
</dd>
<dt>Tom</dt>
<dd> Ok, Extraction.
</dd>
<dt>Stuart</dt>
<dd> <i><b>You have the subject and the object, you want to draw a new relationship, and it allows you to choose a predicate.</b></i>
</dd>
<dt>Ed</dt>
<dd> ...Although, <i><b>Google Refine</b></i> is almost more like an extracting tool.
</dd>
<dt>Tom</dt>
<dd> So, Translation. Non-RDF into RDF, converting...
</dd>
<dt>Karen C</dt>
<dd> D2R, the relational database to RDF.
</dd>
<dt>Tom</dt>
<dd> GRDDL is not really a tool...
</dd>
<dt>Corey</dt>
<dd> But are there tools for using Griddle?
</dd>
<dt>Ed</dt>
<dd> Rapper: it's part of Dave Beckett's RDF tools.
</dd>
<dt>Tom</dt>
<dd> <i><b>Transformation. So, we have selective translation and then actually changing the data, or transforming it into something that goes beyond just translation. We were trying to make the distinction between faithful translation.</b></i>
</dd>
<dt>Karen C</dt>
<dd> <i><b>Google refine.</b></i>
</dd>
<dt>Corey</dt>
<dd> It's in-between extraction and conversion.
</dd>
<dt>Karen C</dt>
<dd> It's like a data cleaning thing. It does content; does it do format?
</dd>
<dt>Ed</dt>
<dd> It will reconcile columns.
</dd>
<dt>Corey</dt>
<dd> And you can write additional plug-ins to get it to validate against anything; it pulls in the URI.
</dd>
<dt>Diane</dt>
<dd> But that's really an improvement thing, right? Because you're going from text-literal to URI.
</dd>
<dt>Karen</dt>
<dd> Does it output RDF?
</dd>
<dt>Ed</dt>
<dd> Not natively, but people at DERI wrote an RDF plug-in. It started its life as Freebase...Gridworks.
</dd>
<dt>Tom</dt>
<dd> Can we call those Triplifiers?
</dd>
<dt>Ed</dt>
<dd> I think the ones up there are good; it just cuts across.
</dd>
<dt>Karen C</dt>
<dd> <i><b>Alot of our tools will do more than one thing.</b></i>
</dd>
<dt>Tom</dt>
<dd> Ok, let's go up to Visualization. Generating simple graphs; validators do that. 
</dd>
<dt>Craig</dt>
<dd> You mean a visual graph?
</dd>
<dt>Tom</dt>
<dd> Yes. 
</dd>
<dt>Karen</dt>
<dd> <i><b>Somehow each of our categories seems to be the name of a tool.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>I don't know if that's good or bad.</b></i>
</dd>
<dt>Karen</dt>
<dd> I don't know either. We need visualization tools for visualization, etc.
</dd>
<dt>Corey</dt>
<dd> Having active categories set us up well for that.
</dd>
<dt>Tom</dt>
<dd> Generating a linked data cloud. I think it was Riley who mentioned she was <i><b>unclear if we're talking about generating things like statistical clustering mechanisms, statistical analysis, things which are not strictly speaking nodes and arcs.</b></i>
</dd>
<dt>Ed</dt>
<dd> <i><b>I think it's both.</b></i>
</dd>
<dt>Tom</dt>
<dd> <i><b>This visualization tool does a number of different kinds of visualization.</b></i>
</dd>
<dt>Ed</dt>
<dd> I think that's good.
</dd>
<dt>Tom</dt>
<dd> Can we go one step down?
</dd>
<dt>Craig</dt>
<dd> Large-scale visualization tool vs.?
</dd>
<dt>Diane</dt>
<dd> Small data vs. big data?
</dd>
<dt>Tom</dt>
<dd> Or maybe a distinction between visualizing nodes and arcs and having some sort of analysis?
</dd>
<dt>Diane</dt>
<dd> Even a spreadsheet is a visualization, then.
</dd>
<dt>Tom</dt>
<dd> Are we done with visualization?
</dd>
<dt>Diane</dt>
<dd> Do you have <i><b>Spotfire</b></i> in there somewhere? <i><b>It's a statistical visualization tool. You give it data, it gives you pictures. You can manipulate the output nicely. Colors, etc.</b></i>
</dd>
<dt>Tom</dt>
<dd> We're making progress here. Looks like we're done with the Composing category, Visualization, Publishing. 
</dd>
<dt>Craig</dt>
<dd> To answer your point, to say it would be sufficient to have Apache probably wouldn't get you there. I'm questioning whether web servers would be out of scope.
</dd>
<dt>Ed</dt>
<dd> <i><b>One thing you might put in there: Linters, tools that check what you've published. You can point the distiller at the page and it will tell you what RDF can get out of it.</b></i>
</dd>
<dt>Corey</dt>
<dd> <i><b>Linters and distillers are actually extractors.</b></i> Why are they called linters? It goes back to short residual fibers that had to do with the cotton gin.
</dd>
<dt>Tom</dt>
<dd> Ok, and Storing: triple store as part of the tool platform, and then triple stores as a learning topic.
</dd>
<dt>Craig</dt>
<dd> LOD-2, if we're differentiating...
</dd>
<dt>Karen</dt>
<dd> It kind of fits with everything, it covers all of them.
</dd>
</dl>

#### Querying 
<dl>
<dt>Tom</dt>
<dd> Let's bookmark that and then figure out how it fits in. We've done everything except for querying, and revisiting this Reading/Understanding to see if there's any tools that we would need for that that we haven't put in the other categories. Querying: what tools do we need?
</dd>
<dt>Karen</dt>
<dd> Have we someplace put things that would help you find properties?
</dd>
<dt>Tom</dt>
<dd> Discovering vocabularies?
</dd>
<dt>Karen</dt>
<dd> Yeah, there are tools for that. We could say tools for discovery of Vocabularies: there are tools that will search across published vocabularies.
</dd>
<dt>Tom</dt>
<dd> Alignments, we've covered that with the mapping tools. 
</dd>
<dt>Craig</dt>
<dd> Some of the query stuff is covered by stores generally. 
</dd>
<dt>Karen</dt>
<dd> It would be nice to have a way to do a structured query.
</dd>
<dt>Tom</dt>
<dd> Query interface?
</dd>
<dt>Karen</dt>
<dd> It also has to be an indexer.
</dd>
<dt>Craig</dt>
<dd> It's hard to say the difference between search and query.
</dd>
<dt>Karen</dt>
<dd> <i><b>Structured and unstructured query. One thing is querying triples as triples, taking the structure into consideration; another is just searching across data. So under querying I think mostly what we were talking about there was structured querying, where you could say I want to find things where this is the subject and this is the predicate.</b></i>
</dd>
<dt>Tom</dt>
<dd> So we could have a structured tool that might use SPARQL but also...
</dd>
<dt>Marjorie</dt>
<dd> X-query.
</dd>
<dt>Tom</dt>
<dd> <i><b>Discovering patterns in data sets; we have it under Visualization and Querying. We had trouble differentiating because there's overlap. We have tools for discovering patterns in data sets that are not visualization tools, or structured query tools.</b></i>
</dd>
<dt>Corey</dt>
<dd> That are also not programming-language type things.
</dd>
<dt>Karen</dt>
<dd> Anything with a prompt. I think what we're hitting on is that we've got it covered, because so many tools do different things.
</dd>
<dt>Tom</dt>
<dd> Consistency checks.
</dd>
<dt>Karen</dt>
<dd> There are reasoners, presumably; they're on different lists of tools that exist.
</dd>
<dt>Tom</dt>
<dd> So, how many tools do we have? Structured query, reasoners, vocabulary discovery, validators, visualization (analytical, nodes and arcs), web servers, conversion, extraction, linters and distillers, mapping, data creation, editor, RDF vocab editors, diagramming tools.
</dd>
<dt>Corey</dt>
<dd> I know we said user services are out of scope, but now I wonder about things like <i><b>Simile</b></i>, whether they fit under Visualization. Some are end-user facing, but they also help visualizing data. Data consumption tools, almost?
</dd>
<dt>Tom</dt>
<dd> Ingestion tools? Where would that go?
</dd>
<dt>Corey</dt>
<dd> The examples I gave fit under Visualization, but I don't know.
</dd>
<dt>Diane</dt>
<dd> Maybe under composing in the sense that you're starting with someone else's data?
</dd>
<dt>Corey</dt>
<dd> But you can use your own. I dropped my own onto a Google map to see geographical distribution.
</dd>
<dt>Diane</dt>
<dd> Starting with someone else's data, or starting from scratch?
</dd>
<dt>Tom</dt>
<dd> <i><b>Harvesting and consumption seems implicit in a lot of these tools.</b></i>
</dd>
<dt>Diane</dt>
<dd> But ingesting for a tool is different than ingesting into your data store.
</dd>
<dt>Corey</dt>
<dd> <i><b>In the past, I've used Simile to get a different view of data on a timeline or a map; I like it under Visualization.</b></i>
</dd>
<dt>Tom</dt>
<dd> How is it different than Spotfire?
</dd>
<dt>Diane</dt>
<dd> <i><b>Spotfire is more analysis using visual tools. You don't use it to go get data.</b></i>
</dd>
<dt>Joseph B</dt>
<dd> <i><b>Simile is kind of a mash-up, a quick-and-dirty.</b></i>
</dd>
<dt>Tom</dt>
<dd> Is there a tool that's going out and finding stuff that is related to what you have, maybe under relationships? Not ringing any bells? I thought that was what you were describing with Simile. No? It looks to me like we have a good starting point; it's not an unmanageably large number of tools.
</dd>
<dt>Stuart</dt>
<dd> And a lot of overlap.
</dd>
<dt>Craig</dt>
<dd> RDF generators in the sense of extraction?
</dd>
<dt>Joseph T</dt>
<dd> She [Karen?] was talking about full-text, right?
</dd>
<dt>Tom</dt>
<dd> So extraction, Open Calais, that sort of thing.
</dd>
<dt>Corey</dt>
<dd> <i><b>Where does a tool like XC fit on this? It's kind of like that generator, only you take data that doesn't fit onto a data model and try to fit it in.</b></i>
</dd>
<dt>Diane</dt>
<dd> <i><b>I think it's a transformation tool; it does change the data, and it's reasonably selective.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Once it's synthesized, something will start to emerge. One thing about the triple store: we did talk about having some kind of a structure that... Alot of the examples take existing data out of systems and expose them. Having a triple store that a learner can interact with his great, but it seems like that is a huge piece of what's going on there, and then not having a relational database on there-the structural piece.</b></i>
</dd>
<dt>Karen</dt>
<dd> But we do have those kinds of tools with the transformation.
</dd>
<dt>Stuart</dt>
<dd> Just having data in RDF that can be used and demo'd.
</dd>
<dt>Tom</dt>
<dd> I wonder if we should consider this a test set. A lot of tools work on data locally, or data stored out there; but a learning lab platform may want to include different types of local storage options.
</dd>
<dt>Mike</dt>
<dd> If we go back to different use cases, yes.
</dd>
<dt>Tom</dt>
<dd> <i><b>So when we do these use cases, if we can try to associate them with tools that would be required to meet the requirements of the use cases, that will be a good way of double-checking the relevance of these.</b></i>
</dd>
<dt>Karen</dt>
<dd> Will all of this go onto the wiki?
</dd>
<dt>Tom</dt>
<dd> Yes. I'll tear into the document that's there now, or create a new document.
</dd>
<dt>Karen</dt>
<dd> That's a good idea; what's there is a lot of different documents.
</dd>
<dt>Tom</dt>
<dd> What else do we need to do? <i><b>The next step is to write this up, collect the use cases.</b></i>
</dd>
<dt>Marcia</dt>
<dd> Are we going to evaluate some of that, or that's in the proposal?
</dd>
<dt>Tom</dt>
<dd> <i><b>The proposal says we're going to put it up on the UW website and solicit review. So what's our strategy for soliciting review? Do we want to target the entire world, or specific people?</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Wasn't there something in there about extending the community?</b></i>
</dd>
<dt>Joseph B</dt>
<dd> <i><b>One strategy is get it to a point, and then invite in some expert reviewers, and then go to a blast.</b></i>
</dd>
<dt>Karen</dt>
<dd> What about <i><b>ALISE -- Association for Library and Information Science Education of the American Library Association?</b></i>
</dd>
<dt>Tom</dt>
<dd> How about the <i><b>iSchool Caucus</b></i>?
</dd>
<dt>Mike</dt>
<dd> <i><b>There are some lists, but they don't get used. I'm not sure that's a very robust. We could do individual schools.</b></i>
</dd>
<dt>Marjorie</dt>
<dd> <i><b>You could send it to the ASIS information architecture list. That's an active group.</b></i>
</dd>
<dt>Karen</dt>
<dd> <i><b>And a lot of those will be professors.</b></i>
</dd>
<dt>Joseph B</dt>
<dd> This is a pretty small community, but especially once we're involved with the library community, cultural heritage.
</dd>
<dt>Corey</dt>
<dd> <i><b>Would it be worth sending this to the LODLAM list?</b></i>
</dd>
<dt>Karen</dt>
<dd> <i><b>I think it would be better to target educators at first.</b></i>
</dd>
<dt>Corey</dt>
<dd> <b><i>But to me I want this to be useful to practitioners, too. People trying to learn this stuff outside of an educational environment.</i></b>
</dd>
<dt>Stuart</dt>
<dd> Ultimately this might be embedded into a larger learning environment. Anyone who gets involved in learning on their own would appreciate even directions on where to go.
</dd>
<dt>Tom</dt>
<dd> <i><b>But it seems the core is the teaching environment.</b></i>
</dd>
<dt>Ed</dt>
<dd> It seems like the iSchool here is well-represented, but maybe there are some others.
</dd>
<dt>Stuart</dt>
<dd> <i><b>Just make a list of people we know are teaching in this area, or struggling to teach in this area.</b></i>
</dd>
<dt>Corey</dt>
<dd> What about the <i><b>W3C Library Linked Data Incubator Group list</b></i>? It's fairly international. 
</dd>
<dt>Stuart</dt>
<dd> The "workshop crowd" are probably more prevalent than faculty in LIS.
</dd>
<dt>Marjorie</dt>
<dd> You might try <i><b>ISKO. Especially the European members are active.</b></i> I went to two seminars on Linked Data last year that they were involved in.
</dd>
<dt>Ed</dt>
<dd> <i><b>I think what you want to look for is commitments from people to engage, use some of the stuff you have as deliverables. See how it works.</b></i>
</dd>
<dt>Tom</dt>
<dd> Get feedback on how it works.
</dd>
<dt>Marjorie</dt>
<dd> What about the <i><b>DCMI</b></i> people?
</dd>
<dt>Stuart</dt>
<dd> The others are the toolmakers, who might look at this list and go, over here already are these 9 things...
</dd>
<dt>Corey</dt>
<dd> What about <i><b>DERI</b></i>?
</dd>
<dt>Ed</dt>
<dd> <i><b>And those people are educators, too.</b></i>
</dd>
<dt>Stuart</dt>
<dd> <i><b>Talis. Paul Walk at UKOLN.</b></i>
</dd>
<dt>Tom</dt>
<dd> And certainly <i><b>David Wood</b></i> (Talis USA no longer exists; its 3roundstones now. We're actually finishing half an hour early?
</dd>
</dl>

